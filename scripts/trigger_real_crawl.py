import asyncio
from app.services.crawler_service import g2b_crawler
from app.db.session import AsyncSessionLocal
from app.db.models import BidAnnouncement
from app.core.logging import logger

async def trigger_and_save():
    print("ğŸš€ G2B í¬ë¡¤ë§ ë° DB ì €ì¥ ì‹œì‘...")
    try:
        announcements = await g2b_crawler.fetch_new_announcements()
        print(f"âœ… {len(announcements)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ (í•„í„°ë§ í†µê³¼)")
        
        async with AsyncSessionLocal() as session:
            for data in announcements:
                # ì¤‘ë³µ ì²´í¬
                from sqlalchemy import select
                stmt = select(BidAnnouncement).where(BidAnnouncement.url == data['url'])
                result = await session.execute(stmt)
                if result.scalar_one_or_none():
                    continue
                
                # ì¤‘ìš”ë„ ê³„ì‚°
                data["importance_score"] = g2b_crawler.calculate_importance_score(data)
                
                # ì €ì¥
                new_announcement = BidAnnouncement(**data)
                session.add(new_announcement)
                await session.commit()
                print(f"ğŸ’¾ ì €ì¥ ì„±ê³µ: {data['title']} (ì²¨ë¶€íŒŒì¼: {'O' if data.get('attachment_content') else 'X'})")
                
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        logger.error(f"Trigger Error: {e}", exc_info=True)

if __name__ == "__main__":
    asyncio.run(trigger_and_save())
